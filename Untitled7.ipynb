{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0c84cd-3ab0-437d-8e03-579480206e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Title, Year, Rating, Director, Stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls056092300/\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "movies = soup.find_all('div', class_='lister-item mode-detail')\n",
    "\n",
    "\n",
    "titles = []\n",
    "years = []\n",
    "ratings = []\n",
    "directors = []\n",
    "stars = []\n",
    "\n",
    "\n",
    "for movie in movies:\n",
    "    title = movie.h3.a.text\n",
    "    year = movie.h3.find('span', class_='lister-item-year').text\n",
    "    rating = movie.strong.text if movie.strong else 'N/A'\n",
    "    director = movie.find('p', class_='').find_all('a')[0].text\n",
    "    star_list = movie.find('p', class_='').find_all('a')[1:]  \n",
    "    star_names = ', '.join([star.text for star in star_list])\n",
    "\n",
    "   \n",
    "    titles.append(title)\n",
    "    years.append(year)\n",
    "    ratings.append(rating)\n",
    "    directors.append(director)\n",
    "    stars.append(star_names)\n",
    "\n",
    "\n",
    "movies_df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Year': years,\n",
    "    'Rating': ratings,\n",
    "    'Director': directors,\n",
    "    'Stars': stars\n",
    "})\n",
    "\n",
    "\n",
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172b148-12ea-4eff-ad7b-574109176c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = 'https://www.patreon.com/coreyms'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    posts = soup.find_all('div', class_='post-class')  \n",
    "\n",
    "    for post in posts:\n",
    "        \n",
    "        heading = post.find('h2').get_text(strip=True)  \n",
    "        \n",
    "       \n",
    "        date = post.find('time').get_text(strip=True)  \n",
    "        \n",
    "        \n",
    "        content = post.find('div', class_='content-class').get_text(strip=True)  \n",
    "        \n",
    "       \n",
    "        likes = post.find('span', class_='likes-class').get_text(strip=True)  \n",
    "\n",
    "        \n",
    "        youtube_link = post.find('a', href=True)['href']  \n",
    "\n",
    "        \n",
    "        print(f'Heading: {heading}')\n",
    "        print(f'Date: {date}')\n",
    "        print(f'Content: {content}')\n",
    "        print(f'Likes: {likes}')\n",
    "        print(f'YouTube Link: {youtube_link}')\n",
    "        print('---')\n",
    "else:\n",
    "    print(f'Failed to retrieve the page. Status code: {response.status_code}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866bd20-f4a2-4704-8bbe-17248cbd7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_house_details(localities):\n",
    "    base_url = \"https://www.nobroker.in\"\n",
    "    house_details = []\n",
    "\n",
    "    for locality in localities:\n",
    "        search_url = f\"{base_url}/flats-for-sale-in-{locality.replace(' ', '-').lower()}\"\n",
    "        response = requests.get(search_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        \n",
    "        listings = soup.find_all('div', class_='card')\n",
    "\n",
    "        for listing in listings:\n",
    "            title = listing.find('h2', class_='title').text.strip() if listing.find('h2', class_='title') else 'N/A'\n",
    "            location = locality\n",
    "            area = listing.find('div', class_='area').text.strip() if listing.find('div', class_='area') else 'N/A'\n",
    "            emi = listing.find('div', class_='emi').text.strip() if listing.find('div', class_='emi') else 'N/A'\n",
    "            price = listing.find('div', class_='price').text.strip() if listing.find('div', class_='price') else 'N/A'\n",
    "\n",
    "            house_details.append({\n",
    "                'Title': title,\n",
    "                'Location': location,\n",
    "                'Area': area,\n",
    "                'EMI': emi,\n",
    "                'Price': price\n",
    "            })\n",
    "\n",
    "    return house_details\n",
    "\n",
    "localities = ['Indira Nagar', 'Jayanagar', 'Rajaji Nagar']\n",
    "houses = scrape_house_details(localities)\n",
    "\n",
    "for house in houses:\n",
    "    print(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefd327-2210-44c5-9955-448fcebaab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = \"https://www.bewakoof.com/bestseller?sort=popular\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "product_containers = soup.find_all(\"div\", class_=\"product-box\")\n",
    "\n",
    "\n",
    "product_details = []\n",
    "\n",
    "\n",
    "for i in range(min(10, len(product_containers))):\n",
    "    product_container = product_containers[i]\n",
    "    \n",
    "    \n",
    "    product_name = product_container.find(\"div\", class_=\"product-name\").text.strip()\n",
    "    \n",
    "    \n",
    "    product_price = product_container.find(\"div\", class_=\"product-price\").text.strip()\n",
    "    \n",
    "    \n",
    "    image_url = product_container.find(\"img\")[\"src\"]\n",
    "    \n",
    "    \n",
    "    product_details.append({\n",
    "        \"name\": product_name,\n",
    "        \"price\": product_price,\n",
    "        \"image_url\": image_url\n",
    "    })\n",
    "\n",
    "\n",
    "for product in product_details:\n",
    "    print(f\"Name: {product['name']}\")\n",
    "    print(f\"Price: {product['price']}\")\n",
    "    print(f\"Image URL: {product['image_url']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65c4fc-5dd6-462b-8ec5-c983d2b9e23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
